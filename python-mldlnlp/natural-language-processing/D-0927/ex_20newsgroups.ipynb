{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyO6BcC5Ij8jep2aMWjsFTvn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 텍스트 분류 - 뉴스\n","---\n","- scikit-learn의 dataset인 20대 뉴스 데이터 분류\n"," "],"metadata":{"id":"2ylL8GfhKX2Q"}},{"cell_type":"markdown","source":["## [1] 데이터 준비\n","---"],"metadata":{"id":"mdUWrT9AKm3V"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"Wd0N9patKrx-","executionInfo":{"status":"ok","timestamp":1664344096909,"user_tz":-540,"elapsed":1109,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["news_data = fetch_20newsgroups(remove=('headers', 'footers'))\n","\n","news_data.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_hXuwZZlKyho","executionInfo":{"status":"ok","timestamp":1664344106395,"user_tz":-540,"elapsed":9488,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}},"outputId":"c815be6f-9221-4b69-9e21-25add3f3ce4e"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["print(f'data = {len(news_data[\"data\"])}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6Ed8qpbK_ye","executionInfo":{"status":"ok","timestamp":1664344106395,"user_tz":-540,"elapsed":23,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}},"outputId":"0db8a789-ae5e-4450-b674-15a1a0f67b61"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["data = 11314\n"]}]},{"cell_type":"code","source":["news_data20 = news_data['data']"],"metadata":{"id":"S4O-TLTNLMnL","executionInfo":{"status":"ok","timestamp":1664344106396,"user_tz":-540,"elapsed":20,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(news_data20[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRcOC6TjLciv","executionInfo":{"status":"ok","timestamp":1664344106397,"user_tz":-540,"elapsed":20,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}},"outputId":"7fa1298f-0950-4ce4-9e3f-b19a709d953f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["I was wondering if anyone out there could enlighten me on this car I saw\n","the other day. It was a 2-door sports car, looked to be from the late 60s/\n","early 70s. It was called a Bricklin. The doors were really small. In addition,\n","the front bumper was separate from the rest of the body. This is \n","all I know. If anyone can tellme a model name, engine specs, years\n","of production, where this car is made, history, or whatever info you\n","have on this funky looking car, please e-mail.\n"]}]},{"cell_type":"code","source":["# 타겟 데이터\n","target = news_data['target']\n","\n","print(f\"target => {len(news_data['target_names'])}개\")\n","for name in news_data[\"target_names\"]:\n","    print(name)\n","print(f'target -> {target}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxVJbjY1Lhka","executionInfo":{"status":"ok","timestamp":1664344106398,"user_tz":-540,"elapsed":18,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}},"outputId":"c5d1bace-514e-4b74-d81d-e48e2a26b955"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["target => 20개\n","alt.atheism\n","comp.graphics\n","comp.os.ms-windows.misc\n","comp.sys.ibm.pc.hardware\n","comp.sys.mac.hardware\n","comp.windows.x\n","misc.forsale\n","rec.autos\n","rec.motorcycles\n","rec.sport.baseball\n","rec.sport.hockey\n","sci.crypt\n","sci.electronics\n","sci.med\n","sci.space\n","soc.religion.christian\n","talk.politics.guns\n","talk.politics.mideast\n","talk.politics.misc\n","talk.religion.misc\n","target -> [7 4 4 ... 3 1 8]\n"]}]},{"cell_type":"code","source":["X = news_data20\n","y = target"],"metadata":{"id":"sKzmus9p6YA5","executionInfo":{"status":"ok","timestamp":1664344106399,"user_tz":-540,"elapsed":15,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["np.unique(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dc1JMqbjKGam","executionInfo":{"status":"ok","timestamp":1664344106399,"user_tz":-540,"elapsed":14,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}},"outputId":"008377af-f115-4e01-e96e-31f9416a5888"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## [2] 데이터 전처리\n","---\n","- 수집 데이터 기반 단어사전 생성\n","- 텍스트 데이터 => 수치 데이터 변환\n","- 데이터 길이 설정\n","- 2진 정수형 변환"],"metadata":{"id":"0HelaXPDNp7c"}},{"cell_type":"markdown","source":["### [2-1] 토큰화와 단어사전 생성"],"metadata":{"id":"KmM41aS6sbA3"}},{"cell_type":"code","source":["import torch\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator"],"metadata":{"id":"QU1qI8eQilfp","executionInfo":{"status":"ok","timestamp":1664344109086,"user_tz":-540,"elapsed":2699,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["tokenizer = get_tokenizer('spacy', 'en_core_web_sm')\n","\n","def yield_tokens(data:list):\n","    for sent in data:\n","        yield tokenizer(sent)\n","\n","vocab = build_vocab_from_iterator(yield_tokens(X), specials=[\"<unk>\"])\n","vocab.set_default_index(vocab['<unk>'])"],"metadata":{"id":"dp-TbmiQfR60","executionInfo":{"status":"ok","timestamp":1664344143857,"user_tz":-540,"elapsed":34776,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["text_pipeline = lambda x: vocab(tokenizer(x))"],"metadata":{"id":"cv8adg_1qwHg","executionInfo":{"status":"ok","timestamp":1664344143859,"user_tz":-540,"elapsed":26,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### [2-2] 데이터 배치와 반복자 생성"],"metadata":{"id":"K6d-0sX2sVMx"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader, random_split\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device('cpu')"],"metadata":{"id":"RtkKSDPXsj0W","executionInfo":{"status":"ok","timestamp":1664344143859,"user_tz":-540,"elapsed":23,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, X, y, train=True):\n","        self.train = train\n","        self.X = X\n","        self.y = y\n","        self.classes = news_data[\"target_names\"]\n","\n","    def __len__(self):\n","        len_dataset = None\n","        len_dataset = len(self.X)\n","        return len_dataset\n","\n","    def __getitem__(self, idx):\n","        X, y = None, None\n","        X = self.X[idx]\n","        if self.train is True:\n","            y = self.y[idx]\n","        return y, X\n","\n","    def split_dataset(self, val_ratio=0.2):\n","        data_size = len(self)\n","        val_set_size = int(data_size * 0.2)\n","        train_set_size = data_size - val_set_size\n","\n","        train_set, val_set = random_split(self, [train_set_size, val_set_size])\n","        return train_set, val_set"],"metadata":{"id":"IR9Lwo7fxSPX","executionInfo":{"status":"ok","timestamp":1664344143860,"user_tz":-540,"elapsed":23,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["dataset = CustomDataset(X, y, train=True)\n","train_dataset, val_dataset = dataset.split_dataset()\n","\n","next(iter(train_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hG06bpOcxSTd","executionInfo":{"status":"ok","timestamp":1664344143860,"user_tz":-540,"elapsed":22,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}},"outputId":"6eba78e3-6953-4acf-e971-c4f996e71a0e"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8,\n"," 'Would anyone out there in DoDland be able to help me out in giving me\\na contact to purchase a pair of military air-borne combat boots (9 1/2\\nD in size).  These boots (so I have read here on rec.moto) are calf\\nheight boots that use only velcro for enclosure.  I have phoned around\\nand nobody seems to carry such an item.  I admit I have not gone into\\nthe deepest bowels of NYC yet for the search but I have made some\\ncalls to several of the bigger army/navy type stores with no luck.\\n\\nAnyone out there know of a place that does carry such an item as well\\nas does mail order?  Any help would be appreciated.')"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["def collate_batch(batch):\n","    label_list, text_list, offsets = [], [], [0]\n","\n","    for (_label, _text) in batch:\n","        label_list.append(_label)\n","        processed_text = torch.tensor(text_pipeline(_text))\n","        text_list.append(processed_text)\n","        offsets.append(processed_text.size(0))\n","    \n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","\n","    text_list = torch.cat(text_list)\n","    return label_list.to(device), text_list.to(device), offsets.to(device)\n","\n","\n","batch_size=32\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"],"metadata":{"id":"gtvJICzhsz2g","executionInfo":{"status":"ok","timestamp":1664344346716,"user_tz":-540,"elapsed":6,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["next(iter(train_dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8CS6-D-os_xl","executionInfo":{"status":"ok","timestamp":1664344350999,"user_tz":-540,"elapsed":7,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}},"outputId":"5f5b0b1b-8b11-4270-a987-8a7776f1d40f"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([ 8,  2, 12, 13,  6, 12, 16,  1, 13,  6,  6,  4, 15,  8,  9, 12,  3,  6,\n","          8, 11,  7, 15,  9, 17,  2, 13, 10,  9, 16,  9,  8,  0]),\n"," tensor([1065,  184,   80,  ...,  372,   75,    1]),\n"," tensor([   0,  145,  175,  455,  522,  573,  713, 1091, 1174, 1266, 1346, 1506,\n","         1595, 3452, 3609, 3797, 4019, 4074, 4147, 4273, 4545, 4882, 5890, 6146,\n","         6154, 6309, 6403, 6531, 6888, 7268, 7463, 8430]))"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["## [3] 모델 생성\n","---"],"metadata":{"id":"3yVBfHW3J4SN"}},{"cell_type":"code","source":["import torch.nn as nn"],"metadata":{"id":"JtpE_dOcKzkq","executionInfo":{"status":"ok","timestamp":1664344143862,"user_tz":-540,"elapsed":17,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class TextClassifier(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, num_classes):\n","        super().__init__()\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.num_classes = num_classes\n","\n","        self.embedding = nn.EmbeddingBag(self.vocab_size, self.embed_dim, sparse=True)\n","        self.rnn = nn.RNN(self.embed_dim, self.hidden_dim, self.num_layers, batch_first=True)\n","        self.linear = nn.Linear(self.hidden_dim, self.num_classes)\n","\n","    def forward(self, text, offsets):\n","        embedded = self.embedding(text, offsets).view(batch_size, -1, self.embed_dim)\n","        hidden = torch.zeros(\n","            self.num_layers, embedded.size(0), self.hidden_dim\n","        ).to(device)\n","        rnn_out, hidden = self.rnn(embedded, hidden)\n","        out = self.linear(rnn_out[:, -1]).view([-1, self.num_classes])\n","\n","        return out"],"metadata":{"id":"K8KqRVYKKyeW","executionInfo":{"status":"ok","timestamp":1664344351632,"user_tz":-540,"elapsed":1,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## [4] 모델 학습\n","---"],"metadata":{"id":"txB0JExEXFgE"}},{"cell_type":"code","source":["vocab_size = len(vocab)\n","embed_dim = 64\n","hidden_dim = 32\n","num_layers = 1\n","num_classes = 20\n","\n","model = TextClassifier(vocab_size, embed_dim, hidden_dim, num_layers, num_classes)"],"metadata":{"id":"4HYsbe6_XMmw","executionInfo":{"status":"ok","timestamp":1664344352128,"user_tz":-540,"elapsed":4,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["learning_rate = 0.01\n","epochs = 20\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 20, gamma=0.5)"],"metadata":{"id":"0D3RSo-hXSxG","executionInfo":{"status":"ok","timestamp":1664344352129,"user_tz":-540,"elapsed":4,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def train(dataloader, epoch):\n","    model.train()\n","    train_acc = 0\n","    train_count = 0\n","    log_interval = 2000\n","    for idx, (labels, texts, offsets) in enumerate(dataloader):\n","        optimizer.zero_grad()\n","\n","        outs = model(texts, offsets)\n","        predicts = torch.argmax(outs, dim=1)\n","        loss = criterion(outs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_acc += (predicts == labels).sum().item()\n","        train_count += labels.size(0)\n","\n","        if idx % log_interval == 0 and idx > 0:\n","            print('| epoch {:3d} | {:5d}/{:5d} batches | accuracy {:8.3f}'.format(epoch, idx, len(dataloader), train_acc / train_count))\n","    scheduler.step()\n"],"metadata":{"id":"p1kV48FOYOu3","executionInfo":{"status":"ok","timestamp":1664344652680,"user_tz":-540,"elapsed":10,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["train(train_dataloader, 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"Id2-SHArc1ru","executionInfo":{"status":"error","timestamp":1664344655701,"user_tz":-540,"elapsed":3027,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}},"outputId":"0d5903bc-b025-4f3f-defa-b54c3a8c9777"},"execution_count":36,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-aa243e028fba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-35-0b0ef8f48455>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-40ec973ad9e3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, offsets)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         hidden = torch.zeros(\n\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, offsets, per_sample_weights)\u001b[0m\n\u001b[1;32m    385\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                                \u001b[0mper_sample_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_last_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                                self.padding_idx)\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding_bag\u001b[0;34m(input, weight, offsets, max_norm, norm_type, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\u001b[0m\n\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m     ret, _, _, _ = torch.embedding_bag(\n\u001b[0;32m-> 2381\u001b[0;31m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_enum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_sample_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_last_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m     )\n\u001b[1;32m   2383\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding_bag)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"a8zVTpsMdESg","executionInfo":{"status":"aborted","timestamp":1664344144907,"user_tz":-540,"elapsed":11,"user":{"displayName":"dsd ss","userId":"11065927055023783290"}}},"execution_count":null,"outputs":[]}]}